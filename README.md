# TDM: Learning Few-Step Diffusion Models by Trajectory Distribution Matching
This is the Official Repository of "Learning Few-Step Diffusion Models by Trajectory Distribution Matching", by *Yihong Luo, Tianyang Hu, Jiacheng Sun, Yujun Cai, Jing Tang*.

## User Study Time!
![user_study](user_study.jpg)
Which one do you think is better? Some images are generated by Pixart-$\alpha$ (50 NFE). Some images are generated by  **TDM (4 NFE)**, distilling from Pixart-$\alpha$ in a data-free way with merely 500 training iterations and 2 A800 hours. All images are generated from the same initial noise.

## Fast Text-to-Video Geneartion

Our proposed TDM can be easily extended to text-to-video.

<p align="center">
  <img src="teacher.gif" alt="Teacher" width="45%">
  <img src="student.gif" alt="Student" width="45%">
</p>

The Left is generated by Cog-VideoX-2B on a single 4090 by around 90s. At the same time, our TDM can generate 25 videos, as shown on the right! 25 times faster without performance degradation! (Note: The noise in the GIF is due to compression.)


## ðŸ”¥TODO 
- Pre-trained Models will be released soon.

## Contact

Please contact Yihong Luo (yluocg@connect.ust.hk) if you have any questions about this work.
