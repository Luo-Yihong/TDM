# TDM: Learning Few-Step Diffusion Models by Trajectory Distribution Matching
This is the Official Repository of "[Learning Few-Step Diffusion Models by Trajectory Distribution Matching](https://arxiv.org/abs/2503.06674)", by *Yihong Luo, Tianyang Hu, Jiacheng Sun, Yujun Cai, Jing Tang*.

## User Study Time!
![user_study](assets/user_study.jpg)
Which one do you think is better? Some images are generated by Pixart-Î± (50 NFE). Some images are generated by  **TDM (4 NFE)**, distilling from Pixart-Î± in a data-free way with merely 500 training iterations and 2 A800 hours. 

<details>

<summary style="color: #1E88E5; cursor: pointer; font-size: 1.2em;"> Click for answer</summary>

<p style="font-size: 1.2em; margin-top: 8px;">Answers of TDM's position (left to right): bottom, bottom, top, bottom, top.</p>

</details>

## Fast Text-to-Video Geneartion

Our proposed TDM can be easily extended to text-to-video.

<p align="center">
  <img src="assets/teacher.gif" alt="Teacher" width="45%">
  <img src="assets/student.gif" alt="Student" width="45%">
</p>

The video on the left was generated by CogVideoX-2B (100 NFE). In the same amount of time, **TDM (4NFE)** can generate 25 videos, as shown on the right, achieving an impressive **25 times speedup  without performance degradation**. (Note: The noise in the GIF is due to compression.)


## ðŸ”¥TODO 
- Pre-trained Models will be released soon.

## Contact

Please contact Yihong Luo (yluocg@connect.ust.hk) if you have any questions about this work.
